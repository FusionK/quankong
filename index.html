<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!--suppress HtmlUnknownTag -->
<html xmlns="http://www.w3.org/1999/xhtml">

  <head>
    <meta http-equiv="content-type" charset="utf-8">

    <script src="js/head.js?prefix="></script>
    <meta name="keywords" content="quankong">
    <title>Quan Kong</title>

    <link rel="stylesheet" href="css/font.css">
    <link rel="stylesheet" href="css/main.css">
    <script src="js/main.js"></script>
    <script src="js/scroll.js"></script>
    <script async type="text/javascript" src="js/google.js"></script>

    <script src='js/google_analytics_auto.js'></script>
    <script src='js/showmore.js'></script>

  </head>

  <body>

    <div class="outercontainer">

      <script src="js/header.js?prefix="></script>
      <header>
        <div class="container header">
          <div class="ftheader text"><a href="#home">Quan Kong</a></div>
          <div class="ftsubheader text"><a href="#publications">Publications</a></div>
          <div class="ftsubheader text"><a href="#home">Home</a></div>
        </div>
      </header>
      <div class="container body">

        <div class="content heading anchor" id="home">
          <div class="img"><img class="img_responsive" src="img/quankong.jpg" alt="Photo"></div>
          <div class="text info">
            <h1>Quan Kong</h1>
            <p/>
            <div>Staff Research Scientist</div>
            <div>Woven by Toyota, Inc.</div>
            <div>Email:&nbsp;</td><td>quan.kong [at] woven-planet (dot) global</div>
            <p/>
            <span><a href="https://scholar.google.co.jp/citations?user=9lqFOsEAAAAJ&hl=ja">Google Scholar</a></span>
            <p/>
          </div>
          <div class="text topic">
            <p/>
            <div class="title">Research Topics</div>
            <ul>
              <li>Vision-Language Models</li>
              <li>Video Understanding</li>
              <li>Multi-Modal Perception</li>
              <li>Self-Supervised Learning</li>
            </ul>
            <p/>
          </div>
          <div class="text">
            <p>I am a staff research scientist at <a href="https://www.woven-planet.global/jp">Woven by Toyota, Inc.</a> working on computer vision.
            My concentric is about Machine Learning and the usage of it on Computer Vision, Large Language Models and Multi-Modal Perception.
            Before working at Woven by Toyota, I was a senior researcher of <a href=https://www.hitachi.com/rd/>Hitachi, Ltd. R&D Japan</a> 
            working on large scale surveillance video analysis system, and a visiting researcher of <a href="https://www.atr.jp/">Department of DBI</a> at <a href="https://www.atr.jp/">ATR</a> working on home automation.
            I finished my Ph.D. and M.S. at <a href="https://www.ist.osaka-u.ac.jp/english/">Osaka University</a>,
            advised by <a href="http://www-nishio.ist.osaka-u.ac.jp/~maekawa/index-e.html">Takuya Maekawa</a>, Norihisa Komoda
            and <a href="http://www-infobiz.ist.osaka-u.ac.jp/en/member/matsushita/">Yasuyuki Matsushita</a>, and my undergraduate degrees at <a href="http://en.xjtu.edu.cn">Xi'an Jiao Tong University</a>.</p>
          </div>
        </div>

        <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script>
        <div class="content" style="z-index:1;position:relative">
          <div class="text">
            <h3 style="margin-bottom:.5em">News</h3>
            <ul id="item-list">
              <li>2025.02: Three papers accepted by CVPR 2025.
              <li>2025.01: One <a href=https://www-sop.inria.fr/members/Francois.Bremond/Postscript/Snehashi_WACV2025.pdf>paper</a> accepted by WACV 2025.
              <li>2024.10: Our proposal about <a href=https://www.nedo.go.jp/content/800014462.pdf>"Multi-Modal Foundation Model for Urban Spatial-Temporal Understanding"</a> accepted by <a href=https://www.meti.go.jp/policy/mono_info_service/geniac/index.html>NEDO GENIAC</a> Project.
              <li>2024.09: <a href=https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/09667.pdf>WTS dataset</a> will be presented at ECCV 2024.
              <li>2024.08: Two papers accepted by ECCV 2024.
              <li>2024.01: <a href=https://github.com/woven-visionai/wts-dataset> WTS: Woven Traffic Safety Dataset</a> has been released and jointly held the competition with <a href=https://www.aicitychallenge.org/>the 8th AI City Challenge</a>@CVPR 2024!
              <li>2024.01: One <a href="https://openaccess.thecvf.com/content/WACV2024/papers/Majhi_OE-CTST_Outlier-Embedded_Cross_Temporal_Scale_Transformer_for_Weakly-Supervised_Video_Anomaly_WACV_2024_paper.pdf">paper</a> accepted by WACV 2024.</li>
              <li>2023.10: One <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_LAC_-_Latent_Action_Composition_for_Skeleton-based_Action_Segmentation_ICCV_2023_paper.pdf">paper</a> accepted by ICCV 2023.</li>
              <li>2023.06: One <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_DeCo_Decomposition_and_Reconstruction_for_Compositional_Temporal_Grounding_via_Coarse-To-Fine_CVPR_2023_paper.pdf">paper</a> accepted by CVPR 2023.</li>
              <li>2023.02: One <a href="https://arxiv.org/pdf/2305.06437.pdf">paper</a> accepted by AAAI 2023.</li>
              <li>2022.07: My previous work about automatic baggage screening system in Hitachi was honored with <a href="https://www.ai-gakkai.or.jp/about/award/">Field Innovation Award</a> from JSAI.</li>
              <li>2022.03: Joined Woven Planet Holdings (now Woven by Toyota, Inc.) from Mar. 2022 working on <a href="https://www.woven-city.global/">Toyota Woven City</a> located around Mt. Fuji.</li>
              <li>2021.04: <a href="https://mmact19.github.io/challenge/">MMAct Challenge</a> will be held on CVPR2021 in conjunction with <a href="http://activity-net.org/challenges/2021/index.html">ActivityNet workshop</a>.</li>
              <li>2020.12: Our team (VAS) achieved Top-1 result on <a href="https://www-nlpir.nist.gov/projects/tvpubs/tv20.slides/tv20.dsdi.slides.pdf">TRECVID2020 DSDI task</a>.</li>
              <li>2020.12: One <a href="https://proceedings.neurips.cc/paper/2020/file/5c9452254bccd24b8ad0bb1ab4408ad1-Paper.pdf">paper</a> accepted by NeurIPS 2020.</li>
              <li>2019.10: Large-scale multi-modal video action understanding dataset <a href="https://mmact19.github.io/2019/">MMAct</a> has been released for use!</li>
            </ul>
            <div id="load-more" style="cursor:pointer; color:blue; text-decoration:underline; margin-top:10px;">More...</div>
          </div>
        </div>

        <div class="content" style="z-index:1;position:relative">
          <div class="text">
            <h3 style="margin-bottom:.5em">Projects</h3>
            <ul style="padding-bottom:1em">
              <li>Multi-Modal Large Language Models for Industry Video Understanding & Agent Applications</li>
              <li>Human-Centered Perception for City</li>
              <li>Human Video Action Understanding for VCA & VSaaS</li>
              <li>Large Scale Surveillance Video Analysis System</li>
              <li>Patent Drawing Retrieval System</li>
              <li>Image Classification/Segmentation for Automatic X-ray Baggage Screening System</li>
              <li>Real World Context Recognition and Its Application for Supporting Interaction in Smart Environment (Ph.D. Thesis)</li>
            </ul>
          </div>
          
        </div>

<!--         <div class="content" style="z-index:1;position:relative">
          <div class="text">
            <h3 style="margin-bottom:.5em">Release</h3>
            <ul style="padding-bottom:1em">
              <li>Successful Development of AI Technology for Human Action Recognition in Video under Low Visibility & Slight Variation in Motion <br>
                (Hitachi News Release, JP/EN) (2019.12.20)</li>
              <li>AIの活用により、X線手荷物検査において安全性を自動識別する技術を開発 <br>
                (Hitachi News Release JP, ITmedia, IMPRESS) (2017.11.01)</li>
              <li>自発的に考えるロボット, 読売新聞（夕刊）(2016.05.19)</li>
            </ul>
          </div>
        </div> -->

        <div class="content" style="z-index:1;position:relative">
          <div class="text">
            <h3 style="margin-bottom:.5em">Professional Service</h3>
            <ul style="padding-bottom:1em">
              <li>Chief research scientist for NEDO GENIAC Project</li>
              <li>IEEE TIP, TPAMI, CVPR, ICCV, ECCV, WACV, AAAI, ICLR, ICMR, IJCAI PC member & Reviewer</li>
              <li>IPSJ JIP (Journal of Information Processing) Editorial Board Member</li>
              <li>IPSJ SIGUBI Committee Member</li>
            </ul>
          </div>
        </div>

        <div class="content anchor" id="publications">
          <div class="text" style="z-index:1;position:relative">
            <h3 style="margin-bottom:0em">
              Publications
                (<a href="" id="select0" onclick="showPubs(0); return false;">show selected</a> /
                <a href="" id="select1" onclick="showPubs(1); return false;">show all</a>
                <a href="" id="select2" onclick="showPubs(2); return false;"></a>)
              
            </h3>
          </div>

          <div id="pubs"></div>

          <script id="pubs_selected" language="text">

            <div class="text anchor">&nbsp;</div>

            <div class="publication">
            <div class="text">
              <div class="title">Synthetic Visual Genome</div>
              <div class="authors">
                <span class="author">Jae Sung Park, Zixian Ma, Linjie Li, Chenhao Zheng, Cheng-Yu Hsieh, Ximing Lu, Khyathi Chandu, <span class="author me">Quan Kong</span>, Norimasa Kobori, Ali Farhadi, Yejin Choi, Ranjay Krishna</span>
              </div>
              <div>
                 <span class="venue">CVPR 2025</span>
               </div>
            </div>
            </div>

            <div class="publication">
            <div class="text">
              <div class="title">Unconstrained 3D gaze estimation with Gaze-Aware 3D Context Encoding</div>
              <div class="authors">
                <span class="author">Yuki Kawana, Shintaro Shiba, <span class="author me">Quan Kong</span>, Norimasa Kobori</span>
              </div>
              <div>
                 <span class="venue">CVPR 2025</span>
               </div>
            </div>
            </div>

            <div class="publication">
            <div class="text">
              <div class="title">Just Dance with π! A Poly-modal Inductor for Weakly-supervised Video Anomaly Detection</div>
              <div class="authors">
                <span class="author">Snehashis Majhi, Giacomo D'Amicantonio, Antitza Dantcheva, <span class="author me">Quan Kong</span>, Lorenzo Garattoni, Gianpiero Francesca, Egor Bondarev, Francois Bremond</span>
              </div>
              <div>
                 <span class="venue">CVPR 2025</span>
               </div>
            </div>
            </div>
              
            <div class="publication">
            <div class="text">
              <div class="title"><a name="scene_coordinate" a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/04383.pdf">Reprojection Errors as Prompts for Efficient Scene Coordinate Regression</a></div>
              <div class="authors">
                <span class="author">Ting-Ru Liu, Hsuan-Kung Yang, Jou-Min Liu, Chun-Wei Huang, Tsung-Chih Chiang, <span class="author me">Quan Kong</span>, Norimasa Kobori, Chun-Yi Lee</span>
              </div>
              <div>
                 <span class="venue">ECCV 2024 |</span>
                 <span class="tag"><a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/04383.pdf">Paper |</a></span>
                 <span class="tag"><a href="https://tingru0203.github.io/egfs/">Project Page |</a></span>
               </div>
            </div>
            </div>
              
            <div class="publication">
            <div class="text">
              <div class="title"><a name="wts" a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/09667.pdf">WTS:A Pedestrian-Centric Traffic Video Dataset for Fine-grained Spatial-Temporal Understanding</a></div>
              <div class="authors">
                <span class="author"><span class="author me">Quan Kong</span>, Yuki Kawana, Rajat Saini, Ashutosh Kumar, Jingjing Pan, Ta Gu, Yohei Ozao, Balazs Opra, David C Anastasiu, Yoichi Sato, Norimasa Kobori</span>
              </div>
              <div>
                 <span class="venue">ECCV 2024 |</span>
                 <span class="tag"><a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/09667.pdf">Paper |</a></span>
                 <span class="tag"><a href="https://woven-visionai.github.io/wts-dataset-homepage/">Project Page |</a></span>
                 <span class="tag"><a href="https://github.com/woven-visionai/wts-dataset">Code |</a></span>
               </div>
            </div>
            </div>
              
            <div class="publication">
            <div class="text">
              <div class="title"><a name="ltn" a href="https://ojs.aaai.org/index.php/AAAI/article/download/25416/25188">Self-Supervised Video Representation Learning via Latent Time Navigation</a></div>
              <div class="authors">
                <span class="author">Di Yang, Yaohui Wang, <span class="author me">Quan Kong</span>, Antitza Dantcheva, Lorenzo Garattoni, Gianpiero Francesca, Francois Bremond</span>
              </div>
              <div>
                 <span class="venue">AAAI 2023 |</span>
                 <span class="tag"><a href="https://ojs.aaai.org/index.php/AAAI/article/download/25416/25188">Paper |</a></span>
               </div>
            </div>
            </div>
              
            <div class="publication">
            <div class="text">
              <div class="title"><a name="lac" a href="http://openaccess.thecvf.com/content/ICCV2023/papers/Yang_LAC_-_Latent_Action_Composition_for_Skeleton-based_Action_Segmentation_ICCV_2023_paper.pdf">LAC-Latent Action Composition for Skeleton-based Action Segmentation</a></div>
              <div class="authors">
                <span class="author">Di Yang, Yaohui Wang, Antitza Dantcheva, <span class="author me">Quan Kong</span>, Lorenzo Garattoni, Gianpiero Francesca, Francois Bremond</span>
              </div>
              <div>
                 <span class="venue">ICCV 2023 |</span>
                 <span class="tag"><a href="http://openaccess.thecvf.com/content/ICCV2023/papers/Yang_LAC_-_Latent_Action_Composition_for_Skeleton-based_Action_Segmentation_ICCV_2023_paper.pdf">Paper |</a></span>
               </div>
            </div>
            </div>
              
            <div class="publication">
            <div class="text">
              <div class="title"><a name="deco" a href="http://openaccess.thecvf.com/content/CVPR2023/papers/Yang_DeCo_Decomposition_and_Reconstruction_for_Compositional_Temporal_Grounding_via_Coarse-To-Fine_CVPR_2023_paper.pdf">Deco: Decomposition and reconstruction for compositional temporal grounding via coarse-to-fine contrastive ranking</a></div>
              <div class="authors">
                <span class="author">Lijin Yang, <span class="author me">Quan Kong</span>, Hsuan-Kung Yang, Wadim Kehl, Yoichi Sato, Norimasa Kobori</span>
              </div>
              <div>
                 <span class="venue">CVPR 2023 |</span>
                 <span class="tag"><a href="http://openaccess.thecvf.com/content/CVPR2023/papers/Yang_DeCo_Decomposition_and_Reconstruction_for_Compositional_Temporal_Grounding_via_Coarse-To-Fine_CVPR_2023_paper.pdf">Paper |</a></span>
               </div>
            </div>
            </div>

            <div class="publication">
            <div class="text">
              <div class="title"><a name="ccl" a href="https://proceedings.neurips.cc/paper/2020/file/5c9452254bccd24b8ad0bb1ab4408ad1-Paper.pdf">Cycle-Contrast for Self-Supervised Video Representation Learning</a></div>
              <div class="authors">
                <span class="author me">Quan Kong</span>,
                <span class="author">Wenpeng Wei, Ziwei Deng, Tomoaki Yoshinaga, Tomokazu Murakami</span>
              </div>
              <div>
                 <span class="venue">NeurIPS 2020 |</span>
                 <span class="tag"><a href="https://proceedings.neurips.cc/paper/2020/file/5c9452254bccd24b8ad0bb1ab4408ad1-Paper.pdf">Paper |</a></span>
                 <span class="tag"><a href="https://mmact19.github.io/ccl/">Project Page |</a></span>
               </div>
            </div>
            </div>

            <div class="publication">
            <div class="text">
              <div class="title"><a name="icra_robot" a href="http://www.lewissoft.com/pdf/ICRA2020/0245.pdf">Anticipating the Start of User Interaction for Service Robot in the Wild</a></div>
              <div class="authors">
                <span class="author">Koichiro Ito, <span class="author me">Quan Kong</span>, Shota Horiguchi, Takashi Sumiyoshi, Kenji Nagamatsu</span>
              </div>
              <div>
                 <span class="venue">ICRA 2020 |</span>
                 <span class="tag"><a href="http://www.lewissoft.com/pdf/ICRA2020/0245.pdf">Paper |</a></span>
               </div>
            </div>
            </div>

            <div class="publication">
            <div class="text">
              <div class="title"><a name="mmact_iccv" a herf="http://openaccess.thecvf.com/content_ICCV_2019/papers/Kong_MMAct_A_Large-Scale_Dataset_for_Cross_Modal_Human_Action_Understanding_ICCV_2019_paper.pdf">MMAct: A Large-Scale Dataset for Cross Modal Human Action Understanding</a></div>
              <div class="authors">
                <span class="author me">Quan Kong</span>,
                <span class="author">Ziming Wu, Ziwei Deng, Klinkigt Martin, Bin Tong, Tomokazu Murakami</span>
              </div>
              <div>
                <span class="venue">ICCV 2019 |</span>
                <span class="tag"><a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Kong_MMAct_A_Large-Scale_Dataset_for_Cross_Modal_Human_Action_Understanding_ICCV_2019_paper.pdf">Paper |</a></span>
                <span class="tag"><a href="https://mmact19.github.io/2019/">Project Page |</a></span>
                <span class="tag"><a href="https://github.com/mmact19/challenge">Code |</a></span>
              </div>
            </div>
            </div>

            <div class="publication">
            <div class="text">
              <div class="title"><a name="activegan" a herf="https://ojs.aaai.org/index.php/AAAI/article/download/4305/4183">Active Generative Adversarial Network for Image Classification</a></div>
              <div class="authors">
                <span class="author me">Quan Kong</span>,
                <span class="author">Bin Tong, Martin Klinkigt, Yuki Watanabe, Naoto Akira, Tomokazu Murakami</span>
              </div>
              <div>
                <span class="venue">AAAI 2019 |</span>
                <span class="tag"><a href="https://ojs.aaai.org/index.php/AAAI/article/download/4305/4183">Paper |</a></span>
              </div>
            </div>
            </div>

            <div class="publication">
            <div class="text">
              <div class="title"><a name="azsl" a herf="https://ojs.aaai.org/index.php/AAAI/article/download/11886/11745">Adversarial Zero-shot Learning With Semantic Augmentation</a></div>
              <div class="authors">
                <span class="author">Bin Tong, Martin Klinkigt, Junwen Chen, Xiankun Cui,
                <span class="author me">Quan Kong</span>,
                Tomokazu Murakami, Yoshiyuki Kobayashi</span>
              </div>
              <div>
                <span class="venue">AAAI 2018 |</span>
                <span class="tag"><a href="https://ojs.aaai.org/index.php/AAAI/article/download/11886/11745">Paper |</a></span>
              </div>
            </div>
            </div>

          </script>

          <script id="pubs_all" language="text">

            <div class="text anchor"><h4>International Conference</h4></div>

            <div class="publication">
            <div class="text">
              <div class="title">Synthetic Visual Genome</div>
              <div class="authors">
                <span class="author">Jae Sung Park, Zixian Ma, Linjie Li, Chenhao Zheng, Cheng-Yu Hsieh, Ximing Lu, Khyathi Chandu, <span class="author me">Quan Kong</span>, Norimasa Kobori, Ali Farhadi, Yejin Choi, Ranjay Krishna</span>
              </div>
              <div>
                 <span class="venue">CVPR 2025</span>
               </div>
            </div>
            </div>

            <div class="publication">
            <div class="text">
              <div class="title">Unconstrained 3D gaze estimation with Gaze-Aware 3D Context Encoding</div>
              <div class="authors">
                <span class="author">Yuki Kawana, Shintaro Shiba, <span class="author me">Quan Kong</span>, Norimasa Kobori</span>
              </div>
              <div>
                 <span class="venue">CVPR 2025</span>
               </div>
            </div>
            </div>

            <div class="publication">
            <div class="text">
              <div class="title">Just Dance with π! A Poly-modal Inductor for Weakly-supervised Video Anomaly Detection</div>
              <div class="authors">
                <span class="author">Snehashis Majhi, Giacomo D'Amicantonio, Antitza Dantcheva, <span class="author me">Quan Kong</span>, Lorenzo Garattoni, Gianpiero Francesca, Egor Bondarev, Francois Bremond</span>
              </div>
              <div>
                 <span class="venue">CVPR 2025</span>
               </div>
            </div>
            </div>
              
            <div class="publication">
            <div class="text">
              <div class="title"><a name="scene_coordinate" a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/04383.pdf">Reprojection Errors as Prompts for Efficient Scene Coordinate Regression</a></div>
              <div class="authors">
                <span class="author">Ting-Ru Liu, Hsuan-Kung Yang, Jou-Min Liu, Chun-Wei Huang, Tsung-Chih Chiang, <span class="author me">Quan Kong</span>, Norimasa Kobori, Chun-Yi Lee</span>
              </div>
              <div>
                 <span class="venue">ECCV 2024 |</span>
                 <span class="tag"><a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/04383.pdf">Paper |</a></span>
                 <span class="tag"><a href="https://tingru0203.github.io/egfs/">Project Page |</a></span>
               </div>
            </div>
            </div>
              
            <div class="publication">
            <div class="text">
              <div class="title"><a name="wts" a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/09667.pdf">WTS:A Pedestrian-Centric Traffic Video Dataset for Fine-grained Spatial-Temporal Understanding</a></div>
              <div class="authors">
                <span class="author"><span class="author me">Quan Kong</span>, Yuki Kawana, Rajat Saini, Ashutosh Kumar, Jingjing Pan, Ta Gu, Yohei Ozao, Balazs Opra, David C Anastasiu, Yoichi Sato, Norimasa Kobori</span>
              </div>
              <div>
                 <span class="venue">ECCV 2024 |</span>
                 <span class="tag"><a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/09667.pdf">Paper |</a></span>
                 <span class="tag"><a href="https://woven-visionai.github.io/wts-dataset-homepage/">Project Page |</a></span>
                 <span class="tag"><a href="https://github.com/woven-visionai/wts-dataset">Code |</a></span>
               </div>
            </div>
            </div>
              
            <div class="publication">
            <div class="text">
              <div class="title"><a name="ltn" a href="https://ojs.aaai.org/index.php/AAAI/article/download/25416/25188">Self-Supervised Video Representation Learning via Latent Time Navigation</a></div>
              <div class="authors">
                <span class="author">Di Yang, Yaohui Wang, <span class="author me">Quan Kong</span>, Antitza Dantcheva, Lorenzo Garattoni, Gianpiero Francesca, Francois Bremond</span>
              </div>
              <div>
                 <span class="venue">AAAI 2023 |</span>
                 <span class="tag"><a href="https://ojs.aaai.org/index.php/AAAI/article/download/25416/25188">Paper |</a></span>
               </div>
            </div>
            </div>
              
            <div class="publication">
            <div class="text">
              <div class="title"><a name="lac" a href="http://openaccess.thecvf.com/content/ICCV2023/papers/Yang_LAC_-_Latent_Action_Composition_for_Skeleton-based_Action_Segmentation_ICCV_2023_paper.pdf">LAC-Latent Action Composition for Skeleton-based Action Segmentation</a></div>
              <div class="authors">
                <span class="author">Di Yang, Yaohui Wang, Antitza Dantcheva, <span class="author me">Quan Kong</span>, Lorenzo Garattoni, Gianpiero Francesca, Francois Bremond</span>
              </div>
              <div>
                 <span class="venue">ICCV 2023 |</span>
                 <span class="tag"><a href="http://openaccess.thecvf.com/content/ICCV2023/papers/Yang_LAC_-_Latent_Action_Composition_for_Skeleton-based_Action_Segmentation_ICCV_2023_paper.pdf">Paper |</a></span>
               </div>
            </div>
            </div>
              
            <div class="publication">
            <div class="text">
              <div class="title"><a name="deco" a href="http://openaccess.thecvf.com/content/CVPR2023/papers/Yang_DeCo_Decomposition_and_Reconstruction_for_Compositional_Temporal_Grounding_via_Coarse-To-Fine_CVPR_2023_paper.pdf">Deco: Decomposition and reconstruction for compositional temporal grounding via coarse-to-fine contrastive ranking</a></div>
              <div class="authors">
                <span class="author">Lijin Yang, <span class="author me">Quan Kong</span>, Hsuan-Kung Yang, Wadim Kehl, Yoichi Sato, Norimasa Kobori</span>
              </div>
              <div>
                 <span class="venue">CVPR 2023 |</span>
                 <span class="tag"><a href="http://openaccess.thecvf.com/content/CVPR2023/papers/Yang_DeCo_Decomposition_and_Reconstruction_for_Compositional_Temporal_Grounding_via_Coarse-To-Fine_CVPR_2023_paper.pdf">Paper |</a></span>
               </div>
            </div>
            </div>
              
            <div class="publication">
            <div class="text">
              <div class="title"><a name="ccl" a href="https://proceedings.neurips.cc/paper/2020/file/5c9452254bccd24b8ad0bb1ab4408ad1-Paper.pdf">Cycle-Contrast for Self-Supervised Video Representation Learning</a></div>
              <div class="authors">
                <span class="author me">Quan Kong</span>,
                <span class="author">Wenpeng Wei, Ziwei Deng, Tomoaki Yoshinaga, Tomokazu Murakami</span>
              </div>
              <div>
                 <span class="venue">NeurIPS 2020 |</span>
                 <span class="tag"><a href="https://proceedings.neurips.cc/paper/2020/file/5c9452254bccd24b8ad0bb1ab4408ad1-Paper.pdf">Paper |</a></span>
                 <span class="tag"><a href="https://mmact19.github.io/ccl/">Project Page |</a></span>
               </div>
            </div>
            </div>

            <div class="publication">
            <div class="text">
              <div class="title"><a name="icra_robot" a href="http://www.lewissoft.com/pdf/ICRA2020/0245.pdf">Anticipating the Start of User Interaction for Service Robot in the Wild</a></div>
              <div class="authors">
                <span class="author">Koichiro Ito, <span class="author me">Quan Kong</span>, Shota Horiguchi, Takashi Sumiyoshi, Kenji Nagamatsu</span>
              </div>
              <div>
                 <span class="venue">ICRA 2020 |</span>
                 <span class="tag"><a href="http://www.lewissoft.com/pdf/ICRA2020/0245.pdf">Paper |</a></span>
               </div>
            </div>
            </div>

            <div class="publication">
            <div class="text">
              <div class="title"><a name="mmact_iccv" a herf="http://openaccess.thecvf.com/content_ICCV_2019/papers/Kong_MMAct_A_Large-Scale_Dataset_for_Cross_Modal_Human_Action_Understanding_ICCV_2019_paper.pdf">MMAct: A Large-Scale Dataset for Cross Modal Human Action Understanding</a></div>
              <div class="authors">
                <span class="author me">Quan Kong</span>,
                <span class="author">Ziming Wu, Ziwei Deng, Klinkigt Martin, Bin Tong, Tomokazu Murakami</span>
              </div>
              <div>
                <span class="venue">ICCV 2019 |</span>
                <span class="tag"><a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Kong_MMAct_A_Large-Scale_Dataset_for_Cross_Modal_Human_Action_Understanding_ICCV_2019_paper.pdf">Paper |</a></span>
                <span class="tag"><a href="https://mmact19.github.io/2019/">Project Page |</a></span>
                <span class="tag"><a href="https://github.com/mmact19/challenge">Code |</a></span>
              </div>
            </div>
            </div>

            <div class="publication">
            <div class="text">
              <div class="title"><a name="efficient" a herf="http://openaccess.thecvf.com/content_ICCVW_2019/papers/TASK-CV/Deng_Towards_Efficient_Instance_Segmentation_with_Hierarchical_Distillation_ICCVW_2019_paper.pdf">Towards Efficient Instance Segmentation with Hierarchical Distillation</a></div>
              <div class="authors">
                <span class="author">Ziwei Deng, <span class="author me">Quan Kong</span>, Tomokazu Murakami</span>
              </div>
              <div>
                <span class="venue">ICCVW 2019 |</span>
                <span class="tag"><a href="http://openaccess.thecvf.com/content_ICCVW_2019/papers/TASK-CV/Deng_Towards_Efficient_Instance_Segmentation_with_Hierarchical_Distillation_ICCVW_2019_paper.pdf">Paper |</a></span>
              </div>
            </div>
            </div>

            <div class="publication">
            <div class="text">
              <div class="title"><a name="activegan" a herf="https://ojs.aaai.org/index.php/AAAI/article/download/4305/4183">Active Generative Adversarial Network for Image Classification</a></div>
              <div class="authors">
                <span class="author me">Quan Kong</span>,
                <span class="author">Bin Tong, Martin Klinkigt, Yuki Watanabe, Naoto Akira, Tomokazu Murakami</span>
              </div>
              <div>
                <span class="venue">AAAI 2019 |</span>
                <span class="tag"><a href="https://ojs.aaai.org/index.php/AAAI/article/download/4305/4183">Paper |</a></span>
              </div>
            </div>
            </div>

            <div class="publication">
            <div class="text">
              <div class="title"><a name="xray" a herf="https://link.springer.com/chapter/10.1007/978-3-030-21074-8_41">Multimodal Deep Neural Networks Based Ensemble Learning for X-Ray Object Recognition</a></div>
              <div class="authors">
                <span class="author me">Quan Kong</span>,
                <span class="author">Naoto Akira, Bin Tong, Yuki Watanabe, Daisuke Matsubara, Tomokazu Murakami</span>
              </div>
              <div>
                <span class="venue">ACCV 2018 |</span>
                <span class="tag"><a href="https://link.springer.com/chapter/10.1007/978-3-030-21074-8_41">Paper |</a></span>
                <div>
                  <span class="highlight">Oral Presentation</span>
                </div>
              </div>
            </div>
            </div>

            <div class="publication">
            <div class="text">
              <div class="title"><a name="azsl" a herf="https://ojs.aaai.org/index.php/AAAI/article/download/11886/11745">Adversarial Zero-shot Learning With Semantic Augmentation</a></div>
              <div class="authors">
                <span class="author">Bin Tong, Martin Klinkigt, Junwen Chen, Xiankun Cui,
                <span class="author me">Quan Kong</span>,
                Tomokazu Murakami, Yoshiyuki Kobayashi</span>
              </div>
              <div>
                <span class="venue">AAAI 2018 |</span>
                <span class="tag"><a href="https://ojs.aaai.org/index.php/AAAI/article/download/11886/11745">Paper |</a></span>
              </div>
            </div>
            </div>

            <div class="publication">
            <div class="text">
              <div class="title"><a name="ubihome" a herf="http://www-mmde.ist.osaka-u.ac.jp/~maekawa/projects/slides/ubicomp2016_kong_en.pdf">Selecting home appliances with smart glass based on contextual information</a></div>
              <div class="authors">
                 <span class="author me">Quan Kong</span>,
                 <span class="author">Takuya Maekawa, Taiki Miyanishi, Takayuki Suyama</span>
              </div>
              <div>
                <span class="venue">Ubicomp 2016 |</span>
                <span class="tag"><a href="http://www-mmde.ist.osaka-u.ac.jp/~maekawa/projects/slides/ubicomp2016_kong_en.pdf">Paper |</a></span>
              </div>
            </div>
            </div>

            <div class="publication">
            <div class="text">
              <div class="title"><a name="egoact" a herf="https://ojs.aaai.org/index.php/AAAI/article/download/10009/9868">Egocentric Video Search via Physical Interactions</a></div>
              <div class="authors">
                <span class="author">Taiki Miyanishi, Junichiro Hirayama, <span class="author me">Quan Kong</span>,
                Takuya Maekawa, Hiroki Moriya, Takayuki Suyama</span>
              </div>
              <div>
                <span class="venue">AAAI 2016 |</span>
                <span class="tag"><a href="https://ojs.aaai.org/index.php/AAAI/article/download/10009/9868">Paper |</a></span>
              </div>
            </div>
            </div>

            <div class="publication">
            <div class="text">
              <div class="title"><a name="outlet" a herf="https://dl.acm.org/doi/abs/10.1145/2632048.2636069">Identifying outlets at which electrical appliances are used by electrical wire sensing to gain positional information about appliance use</a></div>
              <div class="authors">
                <span class="author me">Quan Kong</span>,
                <span class="author">Takuya Maekawa</span>
              </div>
              <div>
                <span class="venue">Ubicomp 2014 |</span>
                <span class="tag"><a href="https://dl.acm.org/doi/abs/10.1145/2632048.2636069">Paper |</a></span>
              </div>
            </div>
            </div>

            <div class="publication">
            <div class="text">
              <div class="title"><a name="wifi" a herf="https://dl.acm.org/doi/abs/10.1145/2493432.2493460">Detecting and correcting WiFi positioning errors</a></div>
              <div class="authors">
                <span class="author">Yuki Tsuda, <span class="author me">Quan Kong</span>, Takuya Maekawa</span>
              </div>
              <div>
                <span class="venue">Ubicomp 2013 |</span>
                <span class="tag"><a href="http://www-nishio.ist.osaka-u.ac.jp/~maekawa/paper/maekawa-ubicomp2013">Paper |</a></span>
              </div>
            </div>
            </div>

            <div class="publication">
            <div class="text">
              <div class="title"><a name="sharing" a herf="http://www.ubicomp.org/ubicomp2013/adjunct/adjunct/p701.pdf">Sharing training data among different activity classes</a></div>
              <div class="authors">
                 <span class="author me">Quan Kong</span>,
                 <span class="author">Takuya Maekawa</span>
              </div>
              <div>
                <span class="venue">UbicompWS 2013 |</span>
                <span class="tag"><a href="http://www.ubicomp.org/ubicomp2013/adjunct/adjunct/p701.pdf">Paper |</a></span>
              </div>
            </div>
            </div>

            <div class="text anchor"><h4>Journal</h4></div>
            
            <div class="publication">
            <div class="text">
              <div class="title">Hierarchical contrastive adaptation for cross-domain object detection</div>
              <div class="authors">
                 <span class="author">Ziwei Deng, <span class="author me">Quan Kong</span>, Naoto Akira, Tomoaki Yoshinaga</span>
              </div>
              <div>
                <span class="venue"Machine Vision and Applications 33, 62 (2022) </span>
              </div>
            </div>
            </div>

            <div class="publication">
            <div class="text">
              <div class="title">Multi-stream Adaptive Graph Convolutional Network Using Inter-and Intra-body Graphs for Two-person Interaction Recognition</div>
              <div class="authors">
                 <span class="author">Yoshiki Ito, Kenichi Morita, <span class="author me">Quan Kong</span>, Tomoaki Yoshinaga</span>
              </div>
              <div>
                <span class="venue">IEEE Access 9, 110670-110682, 2021 </span>
              </div>
            </div>
            </div>
            
            <div class="publication">
            <div class="text">
              <div class="title">Contextual Information Based Home Appliances Selection with Smart Glass</div>
              <div class="authors">
                 <span class="author me">Quan Kong</span>,
                 <span class="author">Takuya Maekawa, Taiki Miyanishi, Takayuki Suyama</span>
              </div>
              <div>
                <span class="venue">Journal of Information Processing 58 (10), 1712-1723, 2016</span>
              </div>
            </div>
            </div>

            <div class="publication">
            <div class="text">
              <div class="title">Identifying Outlets at which Electrical Appliances are Used by Sensing Indoor Electrical System</div>
              <div class="authors">
                 <span class="author me">Quan Kong</span>,
                 <span class="author">Takuya Maekawa</span>
              </div>
              <div>
                <span class="venue">Journal of Information Processing 56 (3), 869-878, 2015</span>
              </div>
            </div>
            </div>

            <div class="publication">
            <div class="text">
              <div class="title">Reusing training data with generative/discriminative hybrid model for practical acceleration-based activity recognition</div>
              <div class="authors">
                 <span class="author me">Quan Kong</span>,
                 <span class="author">Takuya Maekawa</span>
              </div>
              <div>
                <span class="venue">Springer Computing 96 (9), 875-895, 2014</span>
              </div>
            </div>
            </div>

            <div class="publication">
            <div class="text">
              <div class="title">Positioning Error Detection and Correction Methods for Wi-Fi Based Localization</div>
              <div class="authors">
                 <span class="author">Yuki Tsuda, <span class="author me">Quan Kong</span>, Takuya Maekawa</span>
              </div>
              <div>
                <span class="venue">Journal of Information Processing 55 (1), 378-388, 2014</span>
              </div>
            </div>
            </div>

            <div class="publication">
            <div class="text">
              <div class="title">Learning Daily Activity Recognition Model with Sharing Training Data and Semi-Supervised Learning</div>
              <div class="authors">
                 <span class="author me">Quan Kong</span>,
                 <span class="author">Takuya Maekawa</span>
              </div>
              <div>
                <span class="venue">IEEJ TRANSACTIONS ON ELECTRONICS INFORMATION AND SYSTEMS C 134 (5), 711-717, 2014</span>
              </div>
            </div>
            </div>

          </script>

        </div>  <!-- content -->

      </div> <!-- container -->
    </div> <!-- outer container -->

    <style>
      /* Ensure bullet points are visible */
      #item-list {
        list-style-type: disc !important;  /* Force bullets */
        padding-left: 20px;  /* Add spacing for better visibility */
      }
      
      #item-list li {
        display: none;
      }
    </style>
    
    <script>showPubs(0);</script>
    <script>var scroll = new SmoothScroll('a[href*="#"]', {speed: 1000});</script>
    <script>
      $(document).ready(function(){
        let items = $("#item-list li");
        let itemsToShow = 6; // Show first 6 items initially
        let totalItems = items.length;
        let currentIndex = 0;
    
        // Show first set of items
        items.slice(0, itemsToShow).show();
        currentIndex = itemsToShow;
    
        $("#load-more").click(function(){
          // Show next batch of items
          items.slice(currentIndex, currentIndex + itemsToShow).fadeIn();
          currentIndex += itemsToShow;
    
          // Hide "More..." button if all items are shown
          if (currentIndex >= totalItems) {
            $("#load-more").hide();
          }
        });
      });
    </script>

  </body>

</html>
